{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data configuration\n",
      "Train : torch.Size([60000, 28, 28])\n",
      "Test : torch.Size([10000, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanseul/.local/lib/python3.5/site-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/home/hanseul/.local/lib/python3.5/site-packages/torchvision/datasets/mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# data loader\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "testset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "print('Data configuration')\n",
    "print('Train :', trainset.train_data.size())\n",
    "print('Test :', testset.test_data.size())\n",
    "\n",
    "# setting\n",
    "input_n = 28*28\n",
    "hidden_n = 100\n",
    "k = 10\n",
    "\n",
    "n_test = 4\n",
    "n_epoch = 100\n",
    "n_valid = 100\n",
    "batch_size = 100\n",
    "lr = 0.001\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=n_test, shuffle=True, num_workers=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('fc') != -1:\n",
    "        torch.nn.init.kaiming_normal(m.weight.data)\n",
    "        torch.nn.init.kaiming_normal(m.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        # encoding\n",
    "        self.fc1 = nn.Linear(input_n, hidden_n)\n",
    "        # mu & std\n",
    "        self.fc21 = nn.Linear(hidden_n, k)\n",
    "        self.fc22 = nn.Linear(hidden_n, k)\n",
    "        # decoding\n",
    "        self.fc3 = nn.Linear(k, hidden_n)\n",
    "        self.fc4 = nn.Linear(hidden_n, input_n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoding(x)\n",
    "        z = self.reparametrizing(mu, log_var)\n",
    "        recon_x = self.decoding(z)\n",
    "\n",
    "        return recon_x, mu, log_var\n",
    "    def encoding(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        mu = F.relu(self.fc21(x))\n",
    "        log_var = F.relu(self.fc22(x))\n",
    "        return mu, log_var\n",
    "\n",
    "    def reparametrizing(self, mu, log_var):\n",
    "        std = log_var.mul(0.5).exp_()\n",
    "        eps = torch.FloatTensor(std.size()).normal_(mean=0, std=1).cuda()\n",
    "        z = eps.mul(std).add_(mu)\n",
    "        return z\n",
    "\n",
    "    def decoding(self, z):\n",
    "        recon_x = F.relu(self.fc3(z))\n",
    "        recon_x = torch.sigmoid(self.fc4(recon_x))\n",
    "        return recon_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanseul/.local/lib/python3.5/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "if cuda:\n",
    "    net.cuda()\n",
    "net.apply(weight_init)\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss(size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 epoch  100 batch : loss : 29235.98438\n",
      " 0 epoch  200 batch : loss : 21435.80273\n",
      " 0 epoch  300 batch : loss : 20031.08008\n",
      " 0 epoch  400 batch : loss : 19530.05664\n",
      " 0 epoch  500 batch : loss : 19077.30273\n",
      " 0 epoch  600 batch : loss : 18812.79492\n",
      " 1 epoch  100 batch : loss : 18549.74805\n",
      " 1 epoch  200 batch : loss : 18316.49414\n",
      " 1 epoch  300 batch : loss : 18180.91016\n",
      " 1 epoch  400 batch : loss : 17963.85938\n",
      " 1 epoch  500 batch : loss : 17798.96289\n",
      " 1 epoch  600 batch : loss : 17749.62305\n",
      " 2 epoch  100 batch : loss : 17854.85156\n",
      " 2 epoch  200 batch : loss : 17672.07031\n",
      " 2 epoch  300 batch : loss : 17681.30273\n",
      " 2 epoch  400 batch : loss : 17605.52930\n",
      " 2 epoch  500 batch : loss : 17465.05664\n",
      " 2 epoch  600 batch : loss : 17514.88477\n",
      " 3 epoch  100 batch : loss : 17524.81641\n",
      " 3 epoch  200 batch : loss : 17550.63672\n",
      " 3 epoch  300 batch : loss : 17554.84180\n",
      " 3 epoch  400 batch : loss : 17485.53320\n",
      " 3 epoch  500 batch : loss : 17482.11914\n",
      " 3 epoch  600 batch : loss : 17360.63477\n",
      " 4 epoch  100 batch : loss : 17354.53906\n",
      " 4 epoch  200 batch : loss : 17268.13672\n",
      " 4 epoch  300 batch : loss : 17171.17773\n",
      " 4 epoch  400 batch : loss : 17148.98633\n",
      " 4 epoch  500 batch : loss : 17183.08008\n",
      " 4 epoch  600 batch : loss : 17175.19922\n",
      " 5 epoch  100 batch : loss : 17172.77930\n",
      " 5 epoch  200 batch : loss : 17035.27148\n",
      " 5 epoch  300 batch : loss : 17095.49805\n",
      " 5 epoch  400 batch : loss : 17137.21289\n",
      " 5 epoch  500 batch : loss : 17026.11133\n",
      " 5 epoch  600 batch : loss : 17080.47852\n",
      " 6 epoch  100 batch : loss : 17014.61133\n",
      " 6 epoch  200 batch : loss : 17008.60352\n",
      " 6 epoch  300 batch : loss : 17039.08008\n",
      " 6 epoch  400 batch : loss : 17025.96289\n",
      " 6 epoch  500 batch : loss : 16908.84180\n",
      " 6 epoch  600 batch : loss : 17108.85156\n",
      " 7 epoch  100 batch : loss : 17041.50000\n",
      " 7 epoch  200 batch : loss : 16991.91406\n",
      " 7 epoch  300 batch : loss : 17003.98242\n",
      " 7 epoch  400 batch : loss : 16980.86328\n",
      " 7 epoch  500 batch : loss : 16933.16406\n",
      " 7 epoch  600 batch : loss : 16980.14844\n",
      " 8 epoch  100 batch : loss : 16900.62891\n",
      " 8 epoch  200 batch : loss : 16988.45703\n",
      " 8 epoch  300 batch : loss : 16947.13477\n",
      " 8 epoch  400 batch : loss : 16932.24414\n",
      " 8 epoch  500 batch : loss : 16837.01367\n",
      " 8 epoch  600 batch : loss : 16931.91797\n",
      " 9 epoch  100 batch : loss : 16958.11719\n",
      " 9 epoch  200 batch : loss : 16908.83984\n",
      " 9 epoch  300 batch : loss : 16935.72656\n",
      " 9 epoch  400 batch : loss : 16986.84961\n",
      " 9 epoch  500 batch : loss : 16806.00000\n",
      " 9 epoch  600 batch : loss : 16754.34180\n",
      "10 epoch  100 batch : loss : 16754.66211\n",
      "10 epoch  200 batch : loss : 16861.76758\n",
      "10 epoch  300 batch : loss : 16838.89258\n",
      "10 epoch  400 batch : loss : 16830.04492\n",
      "10 epoch  500 batch : loss : 16838.08984\n",
      "10 epoch  600 batch : loss : 16888.65430\n",
      "11 epoch  100 batch : loss : 16764.29297\n",
      "11 epoch  200 batch : loss : 16804.06445\n",
      "11 epoch  300 batch : loss : 16831.37500\n",
      "11 epoch  400 batch : loss : 16827.15039\n",
      "11 epoch  500 batch : loss : 16668.96875\n",
      "11 epoch  600 batch : loss : 16775.22656\n",
      "12 epoch  100 batch : loss : 16729.19922\n",
      "12 epoch  200 batch : loss : 16752.02539\n",
      "12 epoch  300 batch : loss : 16792.32422\n",
      "12 epoch  400 batch : loss : 16744.89258\n",
      "12 epoch  500 batch : loss : 16779.28906\n",
      "12 epoch  600 batch : loss : 16676.91016\n",
      "13 epoch  100 batch : loss : 16753.18555\n",
      "13 epoch  200 batch : loss : 16728.39258\n",
      "13 epoch  300 batch : loss : 16657.77734\n",
      "13 epoch  400 batch : loss : 16759.82031\n",
      "13 epoch  500 batch : loss : 16643.71094\n",
      "13 epoch  600 batch : loss : 16688.87305\n",
      "14 epoch  100 batch : loss : 16610.87109\n",
      "14 epoch  200 batch : loss : 16665.92969\n",
      "14 epoch  300 batch : loss : 16669.96289\n",
      "14 epoch  400 batch : loss : 16697.14062\n",
      "14 epoch  500 batch : loss : 16645.39062\n",
      "14 epoch  600 batch : loss : 16672.16797\n",
      "15 epoch  100 batch : loss : 16577.03516\n",
      "15 epoch  200 batch : loss : 16695.21289\n",
      "15 epoch  300 batch : loss : 16678.60156\n",
      "15 epoch  400 batch : loss : 16587.54883\n",
      "15 epoch  500 batch : loss : 16670.61523\n",
      "15 epoch  600 batch : loss : 16592.03516\n",
      "16 epoch  100 batch : loss : 16581.90234\n",
      "16 epoch  200 batch : loss : 16564.49805\n",
      "16 epoch  300 batch : loss : 16564.49023\n",
      "16 epoch  400 batch : loss : 16635.93164\n",
      "16 epoch  500 batch : loss : 16654.93555\n",
      "16 epoch  600 batch : loss : 16631.47266\n",
      "17 epoch  100 batch : loss : 16572.63281\n",
      "17 epoch  200 batch : loss : 16602.95703\n",
      "17 epoch  300 batch : loss : 16555.01758\n",
      "17 epoch  400 batch : loss : 16597.64844\n",
      "17 epoch  500 batch : loss : 16564.99805\n",
      "17 epoch  600 batch : loss : 16619.59961\n",
      "18 epoch  100 batch : loss : 16514.36523\n",
      "18 epoch  200 batch : loss : 16530.42188\n",
      "18 epoch  300 batch : loss : 16623.33984\n",
      "18 epoch  400 batch : loss : 16618.52148\n",
      "18 epoch  500 batch : loss : 16529.57422\n",
      "18 epoch  600 batch : loss : 16603.23047\n",
      "19 epoch  100 batch : loss : 16640.95898\n",
      "19 epoch  200 batch : loss : 16433.16992\n",
      "19 epoch  300 batch : loss : 16529.17773\n",
      "19 epoch  400 batch : loss : 16609.13281\n",
      "19 epoch  500 batch : loss : 16561.53516\n",
      "19 epoch  600 batch : loss : 16575.84961\n",
      "20 epoch  100 batch : loss : 16597.56055\n",
      "20 epoch  200 batch : loss : 16641.34180\n",
      "20 epoch  300 batch : loss : 16476.64258\n",
      "20 epoch  400 batch : loss : 16464.92383\n",
      "20 epoch  500 batch : loss : 16515.00391\n",
      "20 epoch  600 batch : loss : 16505.11914\n",
      "21 epoch  100 batch : loss : 16533.16992\n",
      "21 epoch  200 batch : loss : 16517.41406\n",
      "21 epoch  300 batch : loss : 16578.99023\n",
      "21 epoch  400 batch : loss : 16595.26953\n",
      "21 epoch  500 batch : loss : 16414.33008\n",
      "21 epoch  600 batch : loss : 16579.88867\n",
      "22 epoch  100 batch : loss : 16522.02344\n",
      "22 epoch  200 batch : loss : 16479.41211\n",
      "22 epoch  300 batch : loss : 16515.96289\n",
      "22 epoch  400 batch : loss : 16494.71289\n",
      "22 epoch  500 batch : loss : 16555.16992\n",
      "22 epoch  600 batch : loss : 16513.76758\n",
      "23 epoch  100 batch : loss : 16484.06250\n",
      "23 epoch  200 batch : loss : 16430.85742\n",
      "23 epoch  300 batch : loss : 16587.44141\n",
      "23 epoch  400 batch : loss : 16428.90039\n",
      "23 epoch  500 batch : loss : 16556.20898\n",
      "23 epoch  600 batch : loss : 16489.26172\n",
      "24 epoch  100 batch : loss : 16518.32812\n",
      "24 epoch  200 batch : loss : 16493.98047\n",
      "24 epoch  300 batch : loss : 16500.77148\n",
      "24 epoch  400 batch : loss : 16497.34766\n",
      "24 epoch  500 batch : loss : 16483.34766\n",
      "24 epoch  600 batch : loss : 16479.74414\n",
      "25 epoch  100 batch : loss : 16469.05664\n",
      "25 epoch  200 batch : loss : 16484.19531\n",
      "25 epoch  300 batch : loss : 16515.60938\n",
      "25 epoch  400 batch : loss : 16501.59961\n",
      "25 epoch  500 batch : loss : 16482.24609\n",
      "25 epoch  600 batch : loss : 16484.56445\n",
      "26 epoch  100 batch : loss : 16448.42383\n",
      "26 epoch  200 batch : loss : 16510.21680\n",
      "26 epoch  300 batch : loss : 16477.44336\n",
      "26 epoch  400 batch : loss : 16389.78320\n",
      "26 epoch  500 batch : loss : 16487.58008\n",
      "26 epoch  600 batch : loss : 16475.97656\n",
      "27 epoch  100 batch : loss : 16448.75000\n",
      "27 epoch  200 batch : loss : 16474.89258\n",
      "27 epoch  300 batch : loss : 16447.41992\n",
      "27 epoch  400 batch : loss : 16467.15039\n",
      "27 epoch  500 batch : loss : 16442.00781\n",
      "27 epoch  600 batch : loss : 16498.14844\n",
      "28 epoch  100 batch : loss : 16455.00781\n",
      "28 epoch  200 batch : loss : 16549.64258\n",
      "28 epoch  300 batch : loss : 16413.84766\n",
      "28 epoch  400 batch : loss : 16439.11719\n",
      "28 epoch  500 batch : loss : 16460.47266\n",
      "28 epoch  600 batch : loss : 16486.01953\n",
      "29 epoch  100 batch : loss : 16495.91016\n",
      "29 epoch  200 batch : loss : 16417.56445\n",
      "29 epoch  300 batch : loss : 16436.65234\n",
      "29 epoch  400 batch : loss : 16460.84766\n",
      "29 epoch  500 batch : loss : 16458.76758\n",
      "29 epoch  600 batch : loss : 16466.11328\n",
      "30 epoch  100 batch : loss : 16455.10156\n",
      "30 epoch  200 batch : loss : 16510.21289\n",
      "30 epoch  300 batch : loss : 16429.14648\n",
      "30 epoch  400 batch : loss : 16414.55273\n",
      "30 epoch  500 batch : loss : 16482.09375\n",
      "30 epoch  600 batch : loss : 16439.26172\n",
      "31 epoch  100 batch : loss : 16473.45312\n",
      "31 epoch  200 batch : loss : 16414.72852\n",
      "31 epoch  300 batch : loss : 16491.64453\n",
      "31 epoch  400 batch : loss : 16394.93750\n",
      "31 epoch  500 batch : loss : 16374.03418\n",
      "31 epoch  600 batch : loss : 16475.84375\n",
      "32 epoch  100 batch : loss : 16420.23438\n",
      "32 epoch  200 batch : loss : 16408.09766\n",
      "32 epoch  300 batch : loss : 16472.26172\n",
      "32 epoch  400 batch : loss : 16428.28125\n",
      "32 epoch  500 batch : loss : 16376.19922\n",
      "32 epoch  600 batch : loss : 16472.85547\n",
      "33 epoch  100 batch : loss : 16364.68359\n",
      "33 epoch  200 batch : loss : 16403.32422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 epoch  300 batch : loss : 16437.08008\n",
      "33 epoch  400 batch : loss : 16406.90430\n",
      "33 epoch  500 batch : loss : 16442.45508\n",
      "33 epoch  600 batch : loss : 16451.50000\n",
      "34 epoch  100 batch : loss : 16507.02930\n",
      "34 epoch  200 batch : loss : 16408.40234\n",
      "34 epoch  300 batch : loss : 16422.60547\n",
      "34 epoch  400 batch : loss : 16390.82031\n",
      "34 epoch  500 batch : loss : 16405.81055\n",
      "34 epoch  600 batch : loss : 16367.20996\n",
      "35 epoch  100 batch : loss : 16441.55273\n",
      "35 epoch  200 batch : loss : 16395.48047\n",
      "35 epoch  300 batch : loss : 16429.13867\n",
      "35 epoch  400 batch : loss : 16471.72656\n",
      "35 epoch  500 batch : loss : 16383.65332\n",
      "35 epoch  600 batch : loss : 16426.16992\n",
      "36 epoch  100 batch : loss : 16438.87500\n",
      "36 epoch  200 batch : loss : 16419.95703\n",
      "36 epoch  300 batch : loss : 16383.69824\n",
      "36 epoch  400 batch : loss : 16464.14453\n",
      "36 epoch  500 batch : loss : 16349.45801\n",
      "36 epoch  600 batch : loss : 16478.13672\n",
      "37 epoch  100 batch : loss : 16334.51855\n",
      "37 epoch  200 batch : loss : 16515.25195\n",
      "37 epoch  300 batch : loss : 16421.84570\n",
      "37 epoch  400 batch : loss : 16395.11914\n",
      "37 epoch  500 batch : loss : 16369.38184\n",
      "37 epoch  600 batch : loss : 16434.73242\n",
      "38 epoch  100 batch : loss : 16426.63672\n",
      "38 epoch  200 batch : loss : 16307.48242\n",
      "38 epoch  300 batch : loss : 16391.55859\n",
      "38 epoch  400 batch : loss : 16480.82422\n",
      "38 epoch  500 batch : loss : 16416.14453\n",
      "38 epoch  600 batch : loss : 16370.34375\n",
      "39 epoch  100 batch : loss : 16342.31445\n",
      "39 epoch  200 batch : loss : 16301.36328\n",
      "39 epoch  300 batch : loss : 16477.09961\n",
      "39 epoch  400 batch : loss : 16414.15234\n",
      "39 epoch  500 batch : loss : 16394.93164\n",
      "39 epoch  600 batch : loss : 16411.90625\n",
      "40 epoch  100 batch : loss : 16450.94336\n",
      "40 epoch  200 batch : loss : 16325.56250\n",
      "40 epoch  300 batch : loss : 16356.68848\n",
      "40 epoch  400 batch : loss : 16442.47266\n",
      "40 epoch  500 batch : loss : 16425.64062\n",
      "40 epoch  600 batch : loss : 16376.32812\n",
      "41 epoch  100 batch : loss : 16383.25977\n",
      "41 epoch  200 batch : loss : 16383.71387\n",
      "41 epoch  300 batch : loss : 16456.25586\n",
      "41 epoch  400 batch : loss : 16350.28613\n",
      "41 epoch  500 batch : loss : 16445.46289\n",
      "41 epoch  600 batch : loss : 16360.11816\n",
      "42 epoch  100 batch : loss : 16347.73438\n",
      "42 epoch  200 batch : loss : 16464.64844\n",
      "42 epoch  300 batch : loss : 16383.10938\n",
      "42 epoch  400 batch : loss : 16388.51172\n",
      "42 epoch  500 batch : loss : 16335.79004\n",
      "42 epoch  600 batch : loss : 16378.56250\n",
      "43 epoch  100 batch : loss : 16416.91992\n",
      "43 epoch  200 batch : loss : 16409.99805\n",
      "43 epoch  300 batch : loss : 16416.76758\n",
      "43 epoch  400 batch : loss : 16331.39453\n",
      "43 epoch  500 batch : loss : 16304.95996\n",
      "43 epoch  600 batch : loss : 16452.48242\n",
      "44 epoch  100 batch : loss : 16316.86230\n",
      "44 epoch  200 batch : loss : 16405.96875\n",
      "44 epoch  300 batch : loss : 16414.08594\n",
      "44 epoch  400 batch : loss : 16424.04297\n",
      "44 epoch  500 batch : loss : 16384.27734\n",
      "44 epoch  600 batch : loss : 16329.84863\n",
      "45 epoch  100 batch : loss : 16351.04492\n",
      "45 epoch  200 batch : loss : 16323.26074\n",
      "45 epoch  300 batch : loss : 16361.99512\n",
      "45 epoch  400 batch : loss : 16357.95605\n",
      "45 epoch  500 batch : loss : 16414.66406\n",
      "45 epoch  600 batch : loss : 16399.69141\n",
      "46 epoch  100 batch : loss : 16474.68164\n",
      "46 epoch  200 batch : loss : 16337.05078\n",
      "46 epoch  300 batch : loss : 16315.79199\n",
      "46 epoch  400 batch : loss : 16399.26172\n",
      "46 epoch  500 batch : loss : 16389.10156\n",
      "46 epoch  600 batch : loss : 16390.85156\n",
      "47 epoch  100 batch : loss : 16337.10254\n",
      "47 epoch  200 batch : loss : 16370.69824\n",
      "47 epoch  300 batch : loss : 16355.30762\n",
      "47 epoch  400 batch : loss : 16354.55371\n",
      "47 epoch  500 batch : loss : 16455.73633\n",
      "47 epoch  600 batch : loss : 16341.05566\n",
      "48 epoch  100 batch : loss : 16386.30078\n",
      "48 epoch  200 batch : loss : 16326.64062\n",
      "48 epoch  300 batch : loss : 16382.16113\n",
      "48 epoch  400 batch : loss : 16384.60156\n",
      "48 epoch  500 batch : loss : 16398.44336\n",
      "48 epoch  600 batch : loss : 16347.50098\n",
      "49 epoch  100 batch : loss : 16435.22852\n",
      "49 epoch  200 batch : loss : 16367.06445\n",
      "49 epoch  300 batch : loss : 16336.40234\n",
      "49 epoch  400 batch : loss : 16419.93164\n",
      "49 epoch  500 batch : loss : 16250.26465\n",
      "49 epoch  600 batch : loss : 16353.75977\n",
      "50 epoch  100 batch : loss : 16352.05078\n",
      "50 epoch  200 batch : loss : 16358.42383\n",
      "50 epoch  300 batch : loss : 16381.92676\n",
      "50 epoch  400 batch : loss : 16374.95117\n",
      "50 epoch  500 batch : loss : 16352.53711\n",
      "50 epoch  600 batch : loss : 16408.28516\n",
      "51 epoch  100 batch : loss : 16405.19922\n",
      "51 epoch  200 batch : loss : 16247.30078\n",
      "51 epoch  300 batch : loss : 16396.60156\n",
      "51 epoch  400 batch : loss : 16342.60547\n",
      "51 epoch  500 batch : loss : 16376.05566\n",
      "51 epoch  600 batch : loss : 16406.08398\n",
      "52 epoch  100 batch : loss : 16388.87695\n",
      "52 epoch  200 batch : loss : 16428.11523\n",
      "52 epoch  300 batch : loss : 16337.81055\n",
      "52 epoch  400 batch : loss : 16335.71973\n",
      "52 epoch  500 batch : loss : 16330.32324\n",
      "52 epoch  600 batch : loss : 16371.14844\n",
      "53 epoch  100 batch : loss : 16336.07617\n",
      "53 epoch  200 batch : loss : 16360.66211\n",
      "53 epoch  300 batch : loss : 16343.59863\n",
      "53 epoch  400 batch : loss : 16365.83203\n",
      "53 epoch  500 batch : loss : 16399.25781\n",
      "53 epoch  600 batch : loss : 16357.76465\n",
      "54 epoch  100 batch : loss : 16284.85449\n",
      "54 epoch  200 batch : loss : 16357.18848\n",
      "54 epoch  300 batch : loss : 16332.02930\n",
      "54 epoch  400 batch : loss : 16419.88672\n",
      "54 epoch  500 batch : loss : 16349.13379\n",
      "54 epoch  600 batch : loss : 16427.95898\n",
      "55 epoch  100 batch : loss : 16362.53418\n",
      "55 epoch  200 batch : loss : 16325.24512\n",
      "55 epoch  300 batch : loss : 16391.70508\n",
      "55 epoch  400 batch : loss : 16410.98242\n",
      "55 epoch  500 batch : loss : 16373.26465\n",
      "55 epoch  600 batch : loss : 16281.06543\n",
      "56 epoch  100 batch : loss : 16431.15039\n",
      "56 epoch  200 batch : loss : 16336.91504\n",
      "56 epoch  300 batch : loss : 16375.04883\n",
      "56 epoch  400 batch : loss : 16292.03613\n",
      "56 epoch  500 batch : loss : 16359.57129\n",
      "56 epoch  600 batch : loss : 16319.14551\n",
      "57 epoch  100 batch : loss : 16317.13867\n",
      "57 epoch  200 batch : loss : 16362.56934\n",
      "57 epoch  300 batch : loss : 16369.87988\n",
      "57 epoch  400 batch : loss : 16338.00195\n",
      "57 epoch  500 batch : loss : 16403.75977\n",
      "57 epoch  600 batch : loss : 16329.13086\n",
      "58 epoch  100 batch : loss : 16399.82031\n",
      "58 epoch  200 batch : loss : 16301.72754\n",
      "58 epoch  300 batch : loss : 16283.00586\n",
      "58 epoch  400 batch : loss : 16330.43848\n",
      "58 epoch  500 batch : loss : 16372.63965\n",
      "58 epoch  600 batch : loss : 16311.60449\n",
      "59 epoch  100 batch : loss : 16373.22754\n",
      "59 epoch  200 batch : loss : 16306.71094\n",
      "59 epoch  300 batch : loss : 16440.37500\n",
      "59 epoch  400 batch : loss : 16383.33887\n",
      "59 epoch  500 batch : loss : 16261.20312\n",
      "59 epoch  600 batch : loss : 16358.21484\n",
      "60 epoch  100 batch : loss : 16312.00977\n",
      "60 epoch  200 batch : loss : 16311.67090\n",
      "60 epoch  300 batch : loss : 16326.79492\n",
      "60 epoch  400 batch : loss : 16338.42480\n",
      "60 epoch  500 batch : loss : 16368.90723\n",
      "60 epoch  600 batch : loss : 16324.20215\n",
      "61 epoch  100 batch : loss : 16339.89746\n",
      "61 epoch  200 batch : loss : 16364.70508\n",
      "61 epoch  300 batch : loss : 16324.31836\n",
      "61 epoch  400 batch : loss : 16284.75879\n",
      "61 epoch  500 batch : loss : 16333.63672\n",
      "61 epoch  600 batch : loss : 16410.27734\n",
      "62 epoch  100 batch : loss : 16272.21680\n",
      "62 epoch  200 batch : loss : 16320.55078\n",
      "62 epoch  300 batch : loss : 16365.00098\n",
      "62 epoch  400 batch : loss : 16342.41113\n",
      "62 epoch  500 batch : loss : 16357.73633\n",
      "62 epoch  600 batch : loss : 16338.31348\n",
      "63 epoch  100 batch : loss : 16317.57227\n",
      "63 epoch  200 batch : loss : 16278.43555\n",
      "63 epoch  300 batch : loss : 16338.57227\n",
      "63 epoch  400 batch : loss : 16336.13574\n",
      "63 epoch  500 batch : loss : 16409.95117\n",
      "63 epoch  600 batch : loss : 16369.69824\n",
      "64 epoch  100 batch : loss : 16258.44824\n",
      "64 epoch  200 batch : loss : 16324.77051\n",
      "64 epoch  300 batch : loss : 16457.95508\n",
      "64 epoch  400 batch : loss : 16309.00879\n",
      "64 epoch  500 batch : loss : 16304.62988\n",
      "64 epoch  600 batch : loss : 16400.98828\n",
      "65 epoch  100 batch : loss : 16355.32617\n",
      "65 epoch  200 batch : loss : 16312.67578\n",
      "65 epoch  300 batch : loss : 16307.38477\n",
      "65 epoch  400 batch : loss : 16336.61621\n",
      "65 epoch  500 batch : loss : 16367.18945\n",
      "65 epoch  600 batch : loss : 16375.69238\n",
      "66 epoch  100 batch : loss : 16349.66309\n",
      "66 epoch  200 batch : loss : 16321.44336\n",
      "66 epoch  300 batch : loss : 16304.61133\n",
      "66 epoch  400 batch : loss : 16291.94336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 epoch  500 batch : loss : 16367.39844\n",
      "66 epoch  600 batch : loss : 16361.85254\n",
      "67 epoch  100 batch : loss : 16371.25879\n",
      "67 epoch  200 batch : loss : 16368.52344\n",
      "67 epoch  300 batch : loss : 16263.20605\n",
      "67 epoch  400 batch : loss : 16333.75977\n",
      "67 epoch  500 batch : loss : 16279.44043\n",
      "67 epoch  600 batch : loss : 16331.39941\n",
      "68 epoch  100 batch : loss : 16336.60254\n",
      "68 epoch  200 batch : loss : 16356.02051\n",
      "68 epoch  300 batch : loss : 16353.10059\n",
      "68 epoch  400 batch : loss : 16365.45312\n",
      "68 epoch  500 batch : loss : 16290.52832\n",
      "68 epoch  600 batch : loss : 16336.33594\n",
      "69 epoch  100 batch : loss : 16324.89258\n",
      "69 epoch  200 batch : loss : 16382.19727\n",
      "69 epoch  300 batch : loss : 16382.17480\n",
      "69 epoch  400 batch : loss : 16323.63965\n",
      "69 epoch  500 batch : loss : 16283.42871\n",
      "69 epoch  600 batch : loss : 16273.19824\n",
      "70 epoch  100 batch : loss : 16403.07617\n",
      "70 epoch  200 batch : loss : 16273.61816\n",
      "70 epoch  300 batch : loss : 16317.25684\n",
      "70 epoch  400 batch : loss : 16224.31348\n",
      "70 epoch  500 batch : loss : 16375.42480\n",
      "70 epoch  600 batch : loss : 16383.34863\n",
      "71 epoch  100 batch : loss : 16262.21680\n",
      "71 epoch  200 batch : loss : 16401.29492\n",
      "71 epoch  300 batch : loss : 16342.56934\n",
      "71 epoch  400 batch : loss : 16352.49316\n",
      "71 epoch  500 batch : loss : 16248.79590\n",
      "71 epoch  600 batch : loss : 16328.89941\n",
      "72 epoch  100 batch : loss : 16275.97363\n",
      "72 epoch  200 batch : loss : 16257.50586\n",
      "72 epoch  300 batch : loss : 16339.36621\n",
      "72 epoch  400 batch : loss : 16369.98730\n",
      "72 epoch  500 batch : loss : 16342.52441\n",
      "72 epoch  600 batch : loss : 16362.74609\n",
      "73 epoch  100 batch : loss : 16281.67383\n",
      "73 epoch  200 batch : loss : 16337.55176\n",
      "73 epoch  300 batch : loss : 16336.76855\n",
      "73 epoch  400 batch : loss : 16348.62109\n",
      "73 epoch  500 batch : loss : 16328.30566\n",
      "73 epoch  600 batch : loss : 16295.40332\n",
      "74 epoch  100 batch : loss : 16249.46680\n",
      "74 epoch  200 batch : loss : 16360.62012\n",
      "74 epoch  300 batch : loss : 16316.29102\n",
      "74 epoch  400 batch : loss : 16317.48340\n",
      "74 epoch  500 batch : loss : 16300.48242\n",
      "74 epoch  600 batch : loss : 16388.57227\n",
      "75 epoch  100 batch : loss : 16380.26465\n",
      "75 epoch  200 batch : loss : 16322.78125\n",
      "75 epoch  300 batch : loss : 16309.62109\n",
      "75 epoch  400 batch : loss : 16272.74121\n",
      "75 epoch  500 batch : loss : 16319.11230\n",
      "75 epoch  600 batch : loss : 16333.33301\n",
      "76 epoch  100 batch : loss : 16302.67090\n",
      "76 epoch  200 batch : loss : 16330.26172\n",
      "76 epoch  300 batch : loss : 16289.62695\n",
      "76 epoch  400 batch : loss : 16375.95312\n",
      "76 epoch  500 batch : loss : 16283.09863\n",
      "76 epoch  600 batch : loss : 16354.57324\n",
      "77 epoch  100 batch : loss : 16324.77734\n",
      "77 epoch  200 batch : loss : 16278.95605\n",
      "77 epoch  300 batch : loss : 16255.53809\n",
      "77 epoch  400 batch : loss : 16354.18066\n",
      "77 epoch  500 batch : loss : 16295.16602\n",
      "77 epoch  600 batch : loss : 16401.50000\n",
      "78 epoch  100 batch : loss : 16299.39258\n",
      "78 epoch  200 batch : loss : 16272.52441\n",
      "78 epoch  300 batch : loss : 16323.07227\n",
      "78 epoch  400 batch : loss : 16352.48340\n",
      "78 epoch  500 batch : loss : 16382.05566\n",
      "78 epoch  600 batch : loss : 16269.25000\n",
      "79 epoch  100 batch : loss : 16239.98730\n",
      "79 epoch  200 batch : loss : 16240.76855\n",
      "79 epoch  300 batch : loss : 16353.51074\n",
      "79 epoch  400 batch : loss : 16402.12891\n",
      "79 epoch  500 batch : loss : 16356.54004\n",
      "79 epoch  600 batch : loss : 16319.77246\n",
      "80 epoch  100 batch : loss : 16354.70508\n",
      "80 epoch  200 batch : loss : 16376.17969\n",
      "80 epoch  300 batch : loss : 16283.76074\n",
      "80 epoch  400 batch : loss : 16306.46094\n",
      "80 epoch  500 batch : loss : 16279.78223\n",
      "80 epoch  600 batch : loss : 16318.97949\n",
      "81 epoch  100 batch : loss : 16248.12793\n",
      "81 epoch  200 batch : loss : 16370.32422\n",
      "81 epoch  300 batch : loss : 16322.16113\n",
      "81 epoch  400 batch : loss : 16279.74121\n",
      "81 epoch  500 batch : loss : 16318.80371\n",
      "81 epoch  600 batch : loss : 16336.12207\n",
      "82 epoch  100 batch : loss : 16308.73047\n",
      "82 epoch  200 batch : loss : 16341.09082\n",
      "82 epoch  300 batch : loss : 16298.92090\n",
      "82 epoch  400 batch : loss : 16309.36621\n",
      "82 epoch  500 batch : loss : 16426.09375\n",
      "82 epoch  600 batch : loss : 16216.11719\n",
      "83 epoch  100 batch : loss : 16272.99219\n",
      "83 epoch  200 batch : loss : 16357.00684\n",
      "83 epoch  300 batch : loss : 16390.77148\n",
      "83 epoch  400 batch : loss : 16296.04004\n",
      "83 epoch  500 batch : loss : 16362.10742\n",
      "83 epoch  600 batch : loss : 16292.66309\n",
      "84 epoch  100 batch : loss : 16282.01465\n",
      "84 epoch  200 batch : loss : 16236.04980\n",
      "84 epoch  300 batch : loss : 16407.71094\n",
      "84 epoch  400 batch : loss : 16325.55859\n",
      "84 epoch  500 batch : loss : 16343.46875\n",
      "84 epoch  600 batch : loss : 16293.96387\n",
      "85 epoch  100 batch : loss : 16292.86328\n",
      "85 epoch  200 batch : loss : 16402.19922\n",
      "85 epoch  300 batch : loss : 16311.71680\n",
      "85 epoch  400 batch : loss : 16309.69922\n",
      "85 epoch  500 batch : loss : 16337.65430\n",
      "85 epoch  600 batch : loss : 16286.74609\n",
      "86 epoch  100 batch : loss : 16335.19238\n",
      "86 epoch  200 batch : loss : 16268.80859\n",
      "86 epoch  300 batch : loss : 16333.54980\n",
      "86 epoch  400 batch : loss : 16289.49609\n",
      "86 epoch  500 batch : loss : 16303.39355\n",
      "86 epoch  600 batch : loss : 16345.47363\n",
      "87 epoch  100 batch : loss : 16254.05762\n",
      "87 epoch  200 batch : loss : 16300.24512\n",
      "87 epoch  300 batch : loss : 16303.98926\n",
      "87 epoch  400 batch : loss : 16308.39746\n",
      "87 epoch  500 batch : loss : 16361.33887\n",
      "87 epoch  600 batch : loss : 16318.65430\n",
      "88 epoch  100 batch : loss : 16256.43359\n",
      "88 epoch  200 batch : loss : 16386.40625\n",
      "88 epoch  300 batch : loss : 16274.82129\n",
      "88 epoch  400 batch : loss : 16236.96387\n",
      "88 epoch  500 batch : loss : 16337.18750\n",
      "88 epoch  600 batch : loss : 16343.26562\n",
      "89 epoch  100 batch : loss : 16308.85449\n",
      "89 epoch  200 batch : loss : 16276.10449\n",
      "89 epoch  300 batch : loss : 16295.76074\n",
      "89 epoch  400 batch : loss : 16291.90137\n",
      "89 epoch  500 batch : loss : 16308.63867\n",
      "89 epoch  600 batch : loss : 16310.43555\n",
      "90 epoch  100 batch : loss : 16266.69824\n",
      "90 epoch  200 batch : loss : 16392.33008\n",
      "90 epoch  300 batch : loss : 16281.03320\n",
      "90 epoch  400 batch : loss : 16305.74219\n",
      "90 epoch  500 batch : loss : 16287.65137\n",
      "90 epoch  600 batch : loss : 16319.20703\n",
      "91 epoch  100 batch : loss : 16286.12695\n",
      "91 epoch  200 batch : loss : 16313.88574\n",
      "91 epoch  300 batch : loss : 16394.82031\n",
      "91 epoch  400 batch : loss : 16230.62695\n",
      "91 epoch  500 batch : loss : 16306.20605\n",
      "91 epoch  600 batch : loss : 16276.67188\n",
      "92 epoch  100 batch : loss : 16272.83105\n",
      "92 epoch  200 batch : loss : 16285.70508\n",
      "92 epoch  300 batch : loss : 16360.44922\n",
      "92 epoch  400 batch : loss : 16326.94727\n",
      "92 epoch  500 batch : loss : 16288.18262\n",
      "92 epoch  600 batch : loss : 16350.25195\n",
      "93 epoch  100 batch : loss : 16325.09180\n",
      "93 epoch  200 batch : loss : 16236.45703\n",
      "93 epoch  300 batch : loss : 16269.48340\n",
      "93 epoch  400 batch : loss : 16279.93457\n",
      "93 epoch  500 batch : loss : 16337.79980\n",
      "93 epoch  600 batch : loss : 16389.64258\n",
      "94 epoch  100 batch : loss : 16350.40137\n",
      "94 epoch  200 batch : loss : 16255.37598\n",
      "94 epoch  300 batch : loss : 16274.73926\n",
      "94 epoch  400 batch : loss : 16271.15918\n",
      "94 epoch  500 batch : loss : 16272.63672\n",
      "94 epoch  600 batch : loss : 16322.75488\n",
      "95 epoch  100 batch : loss : 16355.50586\n",
      "95 epoch  200 batch : loss : 16305.87012\n",
      "95 epoch  300 batch : loss : 16284.94727\n",
      "95 epoch  400 batch : loss : 16256.28320\n",
      "95 epoch  500 batch : loss : 16310.95801\n",
      "95 epoch  600 batch : loss : 16275.33594\n",
      "96 epoch  100 batch : loss : 16376.19238\n",
      "96 epoch  200 batch : loss : 16278.84961\n",
      "96 epoch  300 batch : loss : 16332.84473\n",
      "96 epoch  400 batch : loss : 16271.33594\n",
      "96 epoch  500 batch : loss : 16260.12207\n",
      "96 epoch  600 batch : loss : 16299.57715\n",
      "97 epoch  100 batch : loss : 16299.96191\n",
      "97 epoch  200 batch : loss : 16315.36230\n",
      "97 epoch  300 batch : loss : 16292.30957\n",
      "97 epoch  400 batch : loss : 16327.94043\n",
      "97 epoch  500 batch : loss : 16284.46973\n",
      "97 epoch  600 batch : loss : 16243.81738\n",
      "98 epoch  100 batch : loss : 16344.21973\n",
      "98 epoch  200 batch : loss : 16255.94629\n",
      "98 epoch  300 batch : loss : 16284.45117\n",
      "98 epoch  400 batch : loss : 16323.32422\n",
      "98 epoch  500 batch : loss : 16252.02246\n",
      "98 epoch  600 batch : loss : 16330.27637\n",
      "99 epoch  100 batch : loss : 16272.74121\n",
      "99 epoch  200 batch : loss : 16278.52637\n",
      "99 epoch  300 batch : loss : 16340.58887\n",
      "99 epoch  400 batch : loss : 16332.32227\n",
      "99 epoch  500 batch : loss : 16262.91211\n",
      "99 epoch  600 batch : loss : 16302.55469\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "for e in range(n_epoch):\n",
    "    valid_loss = 0.0\n",
    "    for b, data in enumerate(trainloader):\n",
    "        image, label = data\n",
    "        image = image.view(image.size(0), -1)\n",
    "        image, label = Variable(image), Variable(label)\n",
    "        if cuda:\n",
    "            image, label = image.cuda(), label.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # recon loss\n",
    "        recon_x, mu, log_var = net(image)\n",
    "\n",
    "        # KL loss\n",
    "        # = 0.5 * sum(mu^2 + sigma^2 + log(sigma^2) - 1)\n",
    "        KLD = torch.sum(mu ** 2 + log_var.exp() - (log_var) - 1).mul_(0.5)\n",
    "\n",
    "        loss = criterion(recon_x, image) + KLD\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        valid_loss += loss\n",
    "        if (b % n_valid) == (n_valid - 1):\n",
    "            print('{0:2d} epoch {1:4d} batch : loss : {2:.5f}'.format(e, b + 1, valid_loss / n_valid))\n",
    "            valid_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "fig = plt.figure()\n",
    "\n",
    "test_input, label = next(iter(testloader))\n",
    "test_input = test_input.view(test_input.size(0), -1)\n",
    "test_input = Variable(test_input)\n",
    "\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "test_output, m, l_v = net(test_input)\n",
    "if cuda:\n",
    "    test_input = test_input.cpu().detach()\n",
    "    test_output = test_output.cpu().detach()\n",
    "    \n",
    "row = n_test\n",
    "col = 2\n",
    "\n",
    "for r in range(row):\n",
    "    test_input = test_input.view((test_input.size(0), 28, 28))\n",
    "    test_output = test_output.view((test_output.size(0), 28, 28))\n",
    "    ax = fig.add_subplot(row, col, 2*r+1)\n",
    "    ax.imshow(test_input[r].numpy())\n",
    "    ax.set_xlabel('input')\n",
    "\n",
    "    bx=fig.add_subplot(row, col, 2*r+2)\n",
    "    bx.imshow(test_output[r].cpu().detach().numpy())\n",
    "    bx.set_xlabel('output')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
